#pragma kernel CSRaycast
#pragma kernel CSResolve
#pragma kernel CSTemporal

#define KERNEL_SIZE 16
#define FLT_EPS 0.00000001f;

#include "SSRComputeLib.cginc"
#include "BRDFComputeLib.cginc"

float3 Ray(float3 rayOrigin, float3 rayDirection, float z)
{
    return rayOrigin + rayDirection * z;
}

float Clamp(float2 start,float2 end,float2 delta)
{
    float2 dir = abs(end - start);
    return length(float2(min(dir.x, delta.x), min(dir.y,delta.y)));
}

float4 RayMarch(float3 viewDir, int NumSteps, float3 viewPos, float3 screenPos, float2 uv, float thickness)
{
    float4 rayProj = mul(ProjectionMatrix, float4(viewDir + viewPos, 1.0f));
    float3 rayDir = normalize(rayProj.xyz / rayProj.w - screenPos);
    rayDir.xy *= 0.5;
    float3 rayStart = float3(uv, screenPos.z);
    float2 screenDelta2 = RayCastSize.zw;
    float d = Clamp(rayStart.xy, rayStart.xy + rayDir.xy, screenDelta2);
    float3 samplePos = rayStart + rayDir * d;
    int level = 0;

    float mask = 0;
	[loop]
    for (int i = 0; i < NumSteps; i++)
    {
        float2 currentDelta = screenDelta2 * exp2(level + 1);
        float distnace = Clamp(samplePos.xy, samplePos.xy + rayDir.xy, currentDelta);
        float3 nextSamplePos = samplePos + rayDir * distnace;
        float sampleMinDepth = MinDepth.SampleLevel(samplerMinDepth, nextSamplePos.xy, level);
        float nextDepth = nextSamplePos.z;

		[flatten]
        if (sampleMinDepth < nextDepth)
        {
            level = min(level + 1, 6);
            samplePos = nextSamplePos;
        }
        else
        {
            level--;
        }

		[branch]
        if (level < 0)
        {
            float delta = (-LinearEyeDepth(sampleMinDepth)) - (-LinearEyeDepth(samplePos.z));
            mask = delta <= thickness && i > 0;
            return float4(samplePos, mask);
        }
    }
    return float4(samplePos, mask);
}

RWTexture2D<half4> RaycastResult;
RWTexture2D<half> MaskResult;

float rand(float3 co)
{
    return frac(sin(dot(co.xyz, float3(12.9898, 78.233, 45.5432))) * 43758.5453);
}

[numthreads(KERNEL_SIZE, KERNEL_SIZE, 1)]
void CSRaycast(uint3 id : SV_DispatchThreadID, uint groupIndex : SV_GroupIndex)
{
    float2 uv = (id.xy + 0.5) * RayCastSize.zw;

    float4 worldNormal = GetNormal(uv);
    float3 viewNormal = GetViewNormal(worldNormal.xyz);
    float4 specular = GetSpecular(uv, worldNormal.a);
    float roughness = GetRoughness(specular.a);

    float depth = GetDepth(uv, 0);
		//if(depth == 0) return;
    float3 screenPos = GetScreenPos(uv, depth);
    float3 worldPos = GetWorlPos(screenPos);
    float3 viewPos = GetViewPos(screenPos);

    float2 jitter = Noise.SampleLevel(samplerNoise, (uv + JitterSizeAndOffset.zw) * ScreenSize.xy * NoiseSize.zw, 0).xy; // Blue noise generated by https://github.com/bartwronski/BlueNoiseGenerator/

    float2 Xi = jitter;

    Xi.y = lerp(Xi.y, 0.0, BRDFBias);

    float4 H = TangentToWorld(viewNormal, ImportanceSampleGGX(Xi, roughness));
    float3 dir = reflect(normalize(viewPos), H.xyz);

    float2 rayTraceHit = 0.0;
    float rayTraceZ = 0.0;
    float rayPDF = 0.0;
    float rayMask = 0.0;
    float4 rayTrace = RayMarch(dir, NumSteps, viewPos, screenPos, uv, Thickness);

    rayTraceHit = rayTrace.xy;
    rayTraceZ = rayTrace.z;
    rayPDF = H.w;
    rayMask = rayTrace.w;

    RaycastResult[id.xy] = float4(rayTraceHit, rayTraceZ, rayPDF);
    MaskResult[id.xy] = rayMask;
}

#define RESOLVE_RAD 4
#define RESOLVE_RAD2 8

RWTexture2D<half4> ResolveResult;
Texture2D<half4> RaycastInput;
SamplerState samplerRaycastInput;
Texture2D<half4> MaskInput;
SamplerState samplerMaskInput;

groupshared uint rr_cacheR[(KERNEL_SIZE + RESOLVE_RAD2) * (KERNEL_SIZE + RESOLVE_RAD2)];
groupshared uint rr_cacheG[(KERNEL_SIZE + RESOLVE_RAD2) * (KERNEL_SIZE + RESOLVE_RAD2)];
groupshared uint rr_cacheB[(KERNEL_SIZE + RESOLVE_RAD2) * (KERNEL_SIZE + RESOLVE_RAD2)];
groupshared uint rr_cacheA[(KERNEL_SIZE + RESOLVE_RAD2) * (KERNEL_SIZE + RESOLVE_RAD2)];

void StoreResolveData(uint index, float4 raycast,float4 mask)
{
    rr_cacheR[index] = f32tof16(raycast.r) | f32tof16(mask.r) << 16;
    rr_cacheG[index] = f32tof16(raycast.g) | f32tof16(mask.g) << 16;
    rr_cacheB[index] = f32tof16(raycast.b) | f32tof16(mask.b) << 16;
    rr_cacheA[index] = f32tof16(raycast.a) | f32tof16(mask.a) << 16;
}

void LoadResolveData(uint index, out float4 raycast, out float4 mask)
{
    uint rr = rr_cacheR[index];
    uint gg = rr_cacheG[index];
    uint bb = rr_cacheB[index];
    uint aa = rr_cacheA[index];
    raycast = float4(f16tof32(rr), f16tof32(gg), f16tof32(bb), f16tof32(aa));
    mask = float4(f16tof32(rr >> 16), f16tof32(gg >> 16), f16tof32(bb >> 16), f16tof32(aa >> 16));
}

[numthreads(KERNEL_SIZE + RESOLVE_RAD2, KERNEL_SIZE + RESOLVE_RAD2, 1)]
void CSResolve(uint3 groupId : SV_GroupId, uint groupIndex : SV_GroupIndex, uint3 groupThreadId : SV_GroupThreadID)
{
    uint2 uvInt = (groupId.xy * KERNEL_SIZE) + groupThreadId.xy - RESOLVE_RAD;
    float2 uv = (uvInt.xy + 0.5) * ResolveSize.zw;

    float4 worldNormal = GetNormal(uv);
    float4 specular = GetSpecular(uv, worldNormal.a);
    float roughness = GetRoughness(specular.a);
    float depth = GetDepth(uv,0);
    float3 screenPos = GetScreenPos(uv, depth);
    float3 worldPos = GetWorlPos(screenPos);
    float3 viewPos = GetViewPos(screenPos);
    float3 viewDir = GetViewDir(worldPos);

    float NdotV = saturate(dot(worldNormal.xyz, -viewDir));
    float coneTangent = lerp(0.0, roughness * (1.0 - BRDFBias), NdotV * sqrt(roughness));
    coneTangent *= lerp(saturate(NdotV * 2), 1, sqrt(roughness));

    float maxMipLevel = (float) MaxMipMap - 1.0;
    float4 hitSourcePacked = RaycastInput.SampleLevel(samplerRaycastInput, uv, 0);
    float sourceMip = clamp(log2(coneTangent * length(hitSourcePacked.xy - uv) * max(ScreenSize.x, ScreenSize.y)), 0.0, maxMipLevel);
    float4 maskAndColorPacked = float4(ScreenInput.SampleLevel(samplerScreenInput, hitSourcePacked.xy, sourceMip).rgb, MaskInput.SampleLevel(samplerMaskInput, uv, 0).r);
    StoreResolveData(groupIndex, hitSourcePacked, maskAndColorPacked);

    GroupMemoryBarrierWithGroupSync();

    bool border = groupThreadId.x < RESOLVE_RAD | groupThreadId.y < RESOLVE_RAD | groupThreadId.x >= KERNEL_SIZE + RESOLVE_RAD || groupThreadId.y >= KERNEL_SIZE + RESOLVE_RAD;
    if (border) return;

    float3 viewNormal = GetViewNormal(worldNormal.xyz);

    float4 result = 0.0;
    float weightSum = 0.0;
    float mul = ResolveSize.x / RayCastSize.x;

	[unroll]
    for (int i = 0; i < 4; i++)
    {
        int2 offsetUV = offset[i] * mul * 2;
        //offsetUV = mul(offsetRotationMatrix, offsetUV);

        // "uv" is the location of the current (or "local") pixel. We want to resolve the local pixel using
        // intersections spawned from neighboring pixels. The neighboring pixel is this one:
        int2 neighborGroupThreadId = groupThreadId.xy + offsetUV;
        uint neighborIndex = neighborGroupThreadId.y * (KERNEL_SIZE + RESOLVE_RAD2) + neighborGroupThreadId.x;

        // Now we fetch the intersection point and the PDF that the neighbor's ray hit.
        //float4 hitPacked = RaycastInput.SampleLevel(samplerRaycastInput, neighborUv, 0);
        float4 hitPacked;
        float4 maskScreenPacked;
        LoadResolveData(neighborIndex, hitPacked, maskScreenPacked);
        float2 hitUv = hitPacked.xy;
        float hitZ = hitPacked.z;
        float hitPDF = hitPacked.w;
        float hitMask = maskScreenPacked.a;

        float3 hitViewPos = GetViewPos(GetScreenPos(hitUv, hitZ));

		// We assume that the hit point of the neighbor's ray is also visible for our ray, and we blindly pretend
		// that the current pixel shot that ray. To do that, we treat the hit point as a tiny light source. To calculate
		// a lighting contribution from it, we evaluate the BRDF. Finally, we need to account for the probability of getting
		// this specific position of the "light source", and that is approximately 1/PDF, where PDF comes from the neighbor.
		// Finally, the weight is BRDF/PDF. BRDF uses the local pixel's normal and roughness, but PDF comes from the neighbor.
        float weight = 1.0;
        if (Normalization == 1)
            weight = BRDF_Unity_Weight(normalize(-viewPos) /*V*/, normalize(hitViewPos - viewPos) /*L*/, viewNormal /*N*/, roughness) / max(1e-5, hitPDF);

        float4 sampleColor;
        sampleColor.rgb = maskScreenPacked.rgb;
        sampleColor.a = RayAttenBorder(hitUv, EdgeFactor) * hitMask;

        //fireflies
        sampleColor.rgb /= 1 + Luminance(sampleColor.rgb);

        result += sampleColor * weight;
        weightSum += weight;
    }
    result /= weightSum;

    //fireflies
    result.rgb /= 1 - Luminance(result.rgb);

    ResolveResult[uvInt.xy] = max(1e-5, result);
}

// Based on https://github.com/playdeadgames/temporal

	/*The MIT License (MIT)

	Copyright (c) [2015] [Playdead]

	Permission is hereby granted, free of charge, to any person obtaining a copy
	of this software and associated documentation files (the "Software"), to deal
	in the Software without restriction, including without limitation the rights
	to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
	copies of the Software, and to permit persons to whom the Software is
	furnished to do so, subject to the following conditions:

	The above copyright notice and this permission notice shall be included in all
	copies or substantial portions of the Software.

	THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
	IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
	FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
	AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
	LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
	OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
	SOFTWARE.*/

Texture2D PreviousTemporalInput;
SamplerState samplerPreviousTemporalInput;
RWTexture2D<half4> TemporalResult;

groupshared uint t_cacheR[(KERNEL_SIZE + 2) * (KERNEL_SIZE + 2)];
groupshared uint t_cacheG[(KERNEL_SIZE + 2) * (KERNEL_SIZE + 2)];
groupshared uint t_cacheB[(KERNEL_SIZE + 2) * (KERNEL_SIZE + 2)];
groupshared uint t_cacheA[(KERNEL_SIZE + 2) * (KERNEL_SIZE + 2)];

void Store1TPixel(uint index, float4 pixel)
{
    t_cacheR[index] = asuint(pixel.r);
    t_cacheG[index] = asuint(pixel.g);
    t_cacheB[index] = asuint(pixel.b);
    t_cacheA[index] = asuint(pixel.a);
}

void Load1TPixel(uint index, out float4 pixel)
{
    pixel = asfloat(uint4(t_cacheR[index], t_cacheG[index], t_cacheB[index], t_cacheA[index]));
}

float4 clip_aabb(float3 aabb_min, float3 aabb_max, float4 p, float4 q)
{
    float3 p_clip = 0.5 * (aabb_max + aabb_min);
    float3 e_clip = 0.5 * (aabb_max - aabb_min) + FLT_EPS;

    float4 v_clip = q - float4(p_clip, p.w);
    float3 v_unit = v_clip.xyz / e_clip;
    float3 a_unit = abs(v_unit);
    float ma_unit = max(a_unit.x, max(a_unit.y, a_unit.z));

    if (ma_unit > 1.0)
        return float4(p_clip, p.w) + v_clip / ma_unit;
    else
        return q; // point inside aabb
}

[numthreads(KERNEL_SIZE + 2, KERNEL_SIZE + 2, 1)]
void CSTemporal(uint3 groupId : SV_GroupId, uint3 groupThreadId : SV_GroupThreadID)
{
    uint2 uvInt = (groupId.xy * KERNEL_SIZE) + (groupThreadId.xy - 1);
    float2 uv = saturate((uvInt.xy + 0.5f) * ResolveSize.zw);
    uint groupIndex = groupThreadId.y * (KERNEL_SIZE + 2) + groupThreadId.x;
    float4 current = ScreenInput.SampleLevel(samplerScreenInput, uv, 0);
    Store1TPixel(groupIndex, current);
    GroupMemoryBarrierWithGroupSync();

    bool border = groupThreadId.x == 0 | groupThreadId.y == 0 | groupThreadId.x == KERNEL_SIZE + 1 || groupThreadId.y == KERNEL_SIZE + 1;
    if (border) return;

    float2 unityVelocity = GetVelocity(uv);
    float4 hit = RaycastInput.SampleLevel(samplerRaycastInput,uv,0);

    float depth = GetDepth(uv, 0);
    float unityPrevDepth = GetDepth(uv + unityVelocity, 0);
    float hitDepth = GetDepth(hit.xy, 0);

    float2 reflectionCameraVelocity = CalculateMotion(hitDepth, uv);
    float2 hitCameraVelocity = CalculateMotion(hitDepth, hit.xy);
    float2 cameraVelocity = CalculateMotion(depth, uv);
    float2 hitUnityVelocity = GetVelocity(hit.xy);

    float2 velocityDiff = cameraVelocity - unityVelocity;

    float2 hitVelocityDiff = hitCameraVelocity - hitUnityVelocity;
    float objectVelocityMask = saturate(dot(velocityDiff, velocityDiff) * ScreenSize.x * 100);
    float hitObjectVelocityMask = saturate(dot(hitVelocityDiff, hitVelocityDiff) * ScreenSize.x * 100);
    float2 objectVelocity = unityVelocity * objectVelocityMask;
    float2 hitObjectVelocity = hitUnityVelocity * hitObjectVelocityMask;

    float2 reflectVelocity = lerp(lerp(reflectionCameraVelocity, hitObjectVelocity, hitObjectVelocityMask), objectVelocity, objectVelocityMask);
    float2 velocity = reflectVelocity;
    float2 prevUV = uv - velocity;
		
    float4 previous = PreviousTemporalInput.SampleLevel(samplerPreviousTemporalInput, prevUV,0);

    half4 currentMin = 100;
    half4 currentMax = 0;
    half4 currentAvarage = 0;

	[unroll]
    for (int i = 0; i < 9; i++)
    {
		uint2 uv = groupThreadId.xy + offset[i];
        float4 val;
        Load1TPixel(uv.y * (KERNEL_SIZE + 2) + uv.x, val);
        currentMin = min(currentMin, val);
        currentMax = max(currentMax, val);
        currentAvarage += val;
    }

    currentAvarage /= 9.0;

    previous = clip_aabb(currentMin.xyz, currentMax.xyz, clamp(currentAvarage, currentMin, currentMax), previous);

    float lum0 = Luminance(current.rgb);
    float lum1 = Luminance(previous.rgb);

    float unbiased_diff = abs(lum0 - lum1) / max(lum0, max(lum1, 0.2));
    float unbiased_weight = 1.0 - unbiased_diff;
    float unbiased_weight_sqr = unbiased_weight * unbiased_weight;
    float k_feedback = lerp(TResponseMin, TResponseMax, unbiased_weight_sqr);

    TemporalResult[uvInt.xy] = lerp(current, previous, k_feedback);
}